{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize, blankline_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, wordnet, WordNetLemmatizer\n",
    "import re\n",
    "from nltk import ne_chunk\n",
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = \"\"\"The other text that seems to support the case for Arthur's historical existence is the 10th-century Annales Cambriae, which also link Arthur with the Battle of Badon. The Annales date this battle to 516–518, and also mention the Battle of Camlann, in which Arthur and Medraut (Mordred) were both killed, dated to 537–539. These details have often been used to bolster confidence in the Historia's account and to confirm that Arthur really did fight at Badon.\"\"\"\n",
    "#type(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiTokens = word_tokenize(wiki)\n",
    "#len(wikiTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctTokens = FreqDist()\n",
    "for word in wikiTokens:\n",
    "    distinctTokens[word.lower()]+=1\n",
    "#distinctTokens['arthur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = distinctTokens.most_common(10)\n",
    "#top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiBlanks = blankline_tokenize(wiki)\n",
    "#len(wikiBlanks) #number of paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiBigram = list(nltk.ngrams(wikiTokens, 2))\n",
    "#wikiBigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'use'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "PorterStemmer().stem('used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in wikiTokens:\n",
    "#     print(PorterStemmer().stem(word))\n",
    "#     print(LancasterStemmer().stem(word))\n",
    "#     print(SnowballStemmer('english').stem(word))\n",
    "#     print(WordNetLemmatizer().lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Prime', 'NNP'),\n",
       " ('minister', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('friend', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mine', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "strLine = \"The Prime minister is a good friend of mine\"\n",
    "#identifying grammar like Nouns, verbs , Adjectives, Determiner\n",
    "strTagged = nltk.pos_tag(word_tokenize(strLine))\n",
    "# Named Entity Recognition\n",
    "# strNER = ne_chunk(strTagged)\n",
    "strTagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar = r\"NP: {<DT>?<JJ>*<NN>}\"\n",
    "# strChunker = nltk.RegexpParser(grammar)\n",
    "# strChunker.parse(strTagged)"
   ]
  }
 ]
}